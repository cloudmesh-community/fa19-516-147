##  Implementation of AWS Data Pipeline
Harsha Upadhyay

## Objective

Objective of this project is to design and implement data pipeline to load data into AWS Cloud DB ,apply processing rules for data massaging and provide data for analytics.

ex. Extract , store and provide weekly usage report of Chameleon Cloud for project CH-819337 in DB hosted on AWS cloud(TBD) using AWS pipeline servcies 

## What is AWS Pipeline

As per AWS Docs avaible on the aws site (refernce below) 

"AWS Data Pipeline is a web service that you can use to automate the movement and transformation of data. With AWS Data Pipeline, you can define data-driven workflows, so that tasks can be dependent on the successful completion of previous tasks. You define the parameters of your data transformations and AWS Data Pipeline enforces the logic that you've set up."

https://docs.aws.amazon.com/datapipeline/latest/DeveloperGuide/what-is-datapipeline.html

## Architecture

## Technology Used

Source : Extract Flat File / DB 
Target Infrastucture : AWS Cloud
Target DB : TBD 
API : Rest
Code : Python


## Conclusion
